import { useEffect, useState, useRef, useCallback } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import { useChatStore } from '@/features/chat/store/chatStore';
import { useVoiceStore } from '../store/voiceStore';

import { useGpt } from '../hooks/useGpt';
import { useLanguageStore } from '@/store/languageStore';
import { useParams } from 'react-router-dom';

const apiUrl = import.meta.env.VITE_GPT_API_URL;

const Voice = () => {
  const { listening, transcript, resetTranscript } = useSpeechRecognition();
  const { isCovered, setIsCovered } = useVoiceStore();

  const [detectedCount, setDetectedCount] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  const [capturedText, setCapturedText] = useState('');

  const lastTextTimeRef = useRef<number>(0);
  const keywordIndexRef = useRef<number>(-1);
  const detectedKeywordRef = useRef<string | null>(null);

  const { adminId, kioskId } = useParams();

  const { language } = useLanguageStore();
  const langCode = language === 'en' ? 'en-US' : 'ko-KR';

  // âœ… DEV ì…ë ¥ ìƒíƒœ
  const [devInput, setDevInput] = useState('');

  // ì—¬ëŸ¬ í‚¤ì›Œë“œ ë°°ì—´
  const KEYWORDS =
    language === 'en'
      ? [
          'malang',
          'hello',
          'Malang',
          'my love',
          'Milan',
          'Malone',
          'malang',
          'My love',
          'malone',
          'millione',
          'milan',
        ]
      : [
          'ë§ë‘ì•„',
          'ë¹¨ë‘ì•„',
          'ë¹¨ë‘ ì™€',
          'ë§ë‘í•œ',
          'ë¹¨ë¦¬ ì™€',
          'ë¹¨ë¦¬ì™€',
          'ë¹¨ë‘ì™€',
          'ëª°ë¼',
          'ëª°ë‘',
          'ë§ë‘ì€',
          'ëª°ë‘',
          'ëª°ë¼',
          'ë¹¨ë‘',
        ];

  const addMessage = useChatStore((state) => state.addMessage);
  const updateLastMessage = useChatStore((state) => state.updateLastMessage);
  const setIsCapturing = useChatStore((state) => state.setIsCapturing);
  const isCapturing = useChatStore((state) => state.isCapturing);

  const { sendTextToApi } = useGpt({ apiUrl });

  /**
   * =========================================
   * âœ… DEV ì „ìš©: í‚¤ë³´ë“œ ì…ë ¥ì„ "WebSpeechì™€ ë™ì¼í•œ íë¦„"ìœ¼ë¡œ ì‹¤í–‰
   * =========================================
   * - (í‚¤ì›Œë“œ ê°ì§€ ë°œìƒ ì‹œì ê³¼ ë™ì¼í•˜ê²Œ) ë¹ˆ user ë©”ì‹œì§€ ìƒì„±
   * - updateLastMessageë¡œ í…ìŠ¤íŠ¸ë¥¼ ë„£ì–´ "íƒ€ì´í•‘/ê°±ì‹ " íë¦„ ìœ ì§€
   * - ë§ˆì§€ë§‰ì— isCapturing falseë¡œ ì¢…ë£Œ
   * - WebSpeech ì¢…ë£Œ ì¡°ê±´(2ì´ˆ ë¬´ìŒ) ëŒ€ì‹ , í‚¤ë³´ë“œì—ì„œëŠ” ì¦‰ì‹œ API í˜¸ì¶œ
   *
   * ì›í•˜ëŠ” ê²½ìš°: 2ì´ˆ íƒ€ì´ë¨¸ ë°©ì‹ë„ ê·¸ëŒ€ë¡œ íƒ€ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ”ë°,
   * í‚¤ë³´ë“œëŠ” "ìµœì¢… í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ í™•ì •"ì´ë¼ ë³´í†µ ì¦‰ì‹œ í˜¸ì¶œì´ ìì—°ìŠ¤ëŸ¬ì›€.
   */
  const runDevAsIfWebSpeech = useCallback(
    async (fullText: string) => {
      const now = Date.now();

      // 1) "í‚¤ì›Œë“œ ê°ì§€ í›„ ìº¡ì²˜ ì‹œì‘" ìƒíƒœ ì„¸íŒ…ì„ ê·¸ëŒ€ë¡œ í‰ë‚´
      setIsProcessing(true);
      setDetectedCount((prev) => prev + 1);
      setIsCapturing(true);
      setCapturedText('');
      lastTextTimeRef.current = now;

      // keyword ê´€ë ¨ refë„ ì‹¤ì œ íë¦„ê³¼ ì¶©ëŒ ì—†ê²Œ ë¦¬ì…‹/ì§€ì •
      keywordIndexRef.current = 0;
      detectedKeywordRef.current = 'DEV';

      // 2) WebSpeechì—ì„œ í‚¤ì›Œë“œ ê°ì§€ë˜ë©´ ë¹ˆ ë²„ë¸” ë¨¼ì € ìƒì„±í•˜ëŠ” ê²ƒê³¼ ë™ì¼
      addMessage({
        text: '',
        isUser: true,
        timestamp: now,
      });

      // 3) WebSpeechì˜ transcript ì—…ë°ì´íŠ¸ì²˜ëŸ¼ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
      //    (ì§§ì€ ë”œë ˆì´ë¥¼ ì£¼ë©´ UIê°€ "ì—…ë°ì´íŠ¸ë˜ëŠ”" ëŠë‚Œë„ ë™ì¼)
      window.setTimeout(() => {
        updateLastMessage(fullText);
        setCapturedText(fullText);
        lastTextTimeRef.current = Date.now();
      }, 30);

      // 4) í‚¤ë³´ë“œëŠ” ìµœì¢…ê°’ì´ í™•ì •ì´ë¯€ë¡œ, WebSpeechì˜ "ë¬´ìŒ 2ì´ˆ í›„ ì²˜ë¦¬" ëŒ€ì‹  ì¦‰ì‹œ ì²˜ë¦¬
      //    (ì›í•˜ë©´ ì•„ë˜ë¥¼ setTimeout(2000)ìœ¼ë¡œ ë°”ê¿”ì„œ ì™„ì „íˆ ë™ì¼í•˜ê²Œë„ ê°€ëŠ¥)
      try {
        await sendTextToApi(fullText, adminId, kioskId);
      } catch (err) {
        console.error('Error processing DEV input:', err);
      } finally {
        // 5) ì¢…ë£Œ ì²˜ë¦¬(ì›ë˜ WebSpeech ì¢…ë£Œ ì²˜ë¦¬ì™€ ë™ì¼í•˜ê²Œ ì •ë¦¬)
        setIsCapturing(false);
        setIsProcessing(false);

        resetTranscript();
        keywordIndexRef.current = -1;
        detectedKeywordRef.current = null;
        setCapturedText('');
      }
    },
    [
      addMessage,
      updateLastMessage,
      sendTextToApi,
      adminId,
      kioskId,
      resetTranscript,
      setIsCapturing,
      setIsProcessing,
    ]
  );

  /**
   * ğŸ§  ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ê°ì§€ (WebSpeech transcript)
   */
  useEffect(() => {
    if (transcript) {
      lastTextTimeRef.current = Date.now();

      if (isCapturing && keywordIndexRef.current !== -1 && detectedKeywordRef.current) {
        const textAfterKeyword = transcript
          .slice(keywordIndexRef.current + detectedKeywordRef.current.length)
          .trim();

        setCapturedText(textAfterKeyword);
        updateLastMessage(textAfterKeyword);
      }
    }
  }, [transcript, isCapturing, updateLastMessage]);

  /**
   * ğŸ” ì¼ì • ì‹œê°„ í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ì¸ì‹ ì¢…ë£Œ ë° ì²˜ë¦¬ (WebSpeech)
   */
  useEffect(() => {
    if (!isCapturing) return;

    const checkInterval = setInterval(() => {
      const now = Date.now();
      if (now - lastTextTimeRef.current > 2000) {
        setIsCapturing(false);
        setIsProcessing(false);

        if (capturedText) {
          sendTextToApi(capturedText, adminId, kioskId).catch((err) => {
            console.error('Error processing voice input:', err);
          });
        }

        resetTranscript();
        keywordIndexRef.current = -1;
        detectedKeywordRef.current = null;
        setCapturedText('');
      }
    }, 100);

    return () => clearInterval(checkInterval);
  }, [isCapturing, capturedText, sendTextToApi, adminId, kioskId, resetTranscript, setIsCapturing]);

  /**
   * ğŸ¯ í‚¤ì›Œë“œ ê°ì§€ (WebSpeech transcript)
   */
  useEffect(() => {
    if (!transcript || isProcessing) return;

    let foundKeyword: string | null = null;
    let foundIndex = -1;

    for (const keyword of KEYWORDS) {
      const idx = transcript.indexOf(keyword);
      if (idx !== -1) {
        foundKeyword = keyword;
        foundIndex = idx;
        break;
      }
    }

    if (foundKeyword && keywordIndexRef.current === -1) {
      setIsProcessing(true);
      setDetectedCount((prev) => prev + 1);
      setIsCapturing(true);
      setCapturedText('');
      lastTextTimeRef.current = Date.now();
      keywordIndexRef.current = foundIndex;
      detectedKeywordRef.current = foundKeyword;

      addMessage({
        text: '',
        isUser: true,
        timestamp: Date.now(),
      });
    }
  }, [transcript, isProcessing, KEYWORDS, addMessage, setIsCapturing]);

  // ğŸ”‡ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë§ˆì´í¬ ì •ì§€
  useEffect(() => {
    return () => {
      SpeechRecognition.stopListening();
    };
  }, []);

  // ğŸ§ listening ìƒíƒœ, transcript ì‹¤ì‹œê°„ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
  useEffect(() => {
    console.log('ğŸ§ listening ìƒíƒœ:', listening);
    console.log('ğŸ—£ï¸ transcript:', transcript);
  }, [listening, transcript]);

  return (
    <div className="p-6 h-fit rounded-xl shadow-lg bg-white text-center">
      {/* âœ… DEV ì „ìš© í‚¤ë³´ë“œ ì…ë ¥ UI */}
      {process.env.NODE_ENV === 'development' && (
        <div className="mb-4 p-3 rounded-lg border border-indigo-200 bg-indigo-50 text-left">
          <div className="text-xs text-indigo-700 mb-2">
            DEV: í‚¤ë³´ë“œ ì…ë ¥ì„ WebSpeech íŒŒì´í”„ë¼ì¸ì²˜ëŸ¼ ì²˜ë¦¬ (ë¹ˆ ë²„ë¸” ìƒì„± â†’ updateLastMessage â†’ API í˜¸ì¶œ)
          </div>

          <div className="flex gap-2">
            <textarea
              className="flex-1 p-2 border rounded-md text-sm resize-none"
              rows={2}
              placeholder="DEV: ì—¬ê¸°ì— ë¬¸ì¥ ì…ë ¥ í›„ Enter (Shift+Enter ì¤„ë°”ê¿ˆ)"
              value={devInput}
              onChange={(e) => setDevInput(e.target.value)}
              onKeyDown={(e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                  e.preventDefault();
                  const text = devInput.trim();
                  if (!text) return;
                  setDevInput('');
                  runDevAsIfWebSpeech(text);
                }
              }}
            />
            <button
              className="px-4 rounded-md bg-indigo-600 text-white text-sm hover:bg-indigo-700"
              onClick={() => {
                const text = devInput.trim();
                if (!text) return;
                setDevInput('');
                runDevAsIfWebSpeech(text);
              }}
            >
              Send
            </button>
          </div>
        </div>
      )}

      {isCovered && (
        <div
          className="
            absolute top-0 left-0 w-screen h-screen p-6
            flex flex-col items-center justify-center
            cursor-pointer
            bg-white/80
            border-4 border-indigo-500
            rounded-none
            shadow-xl
            backdrop-blur-md
          "
          onClick={() => {
            setIsCovered(false);
            return SpeechRecognition.startListening({
              continuous: true,
              language: langCode,
            });
          }}
        >
          <div className="absolute top-6 left-6 text-2xl font-bold text-indigo-600 select-none drop-shadow-md">
            Mallang Order
          </div>

          <div className="absolute top-6 right-6">
            <button
              onClick={(e) => {
                e.stopPropagation();
                setIsCovered(true);
                useLanguageStore.setState((state) => ({
                  language: state.language === 'en' ? 'ko' : 'en',
                }));
              }}
              className="px-4 py-2 rounded-lg bg-indigo-600 text-white font-semibold shadow hover:bg-indigo-700 transition"
            >
              {language === 'en' ? 'í•œê¸€' : 'ENG'}
            </button>
          </div>

          <div
            className="w-[300px] h-[300px] rounded-full bg-gradient-to-br from-indigo-200 to-indigo-400
              text-indigo-900 font-extrabold text-7xl tracking-tight flex items-center justify-center
              shadow-[0_10px_30px_rgba(99,102,241,0.4)] border border-indigo-300 relative overflow-hidden"
          >
            <span
              style={{
                background: 'linear-gradient(135deg, #5c6ac4 0%, #3b43a9 100%)',
                WebkitBackgroundClip: 'text',
                WebkitTextFillColor: 'transparent',
                filter: 'drop-shadow(0 1px 1px rgba(0,0,0,0.15))',
              }}
            >
              ML
            </span>
          </div>

          <p className="text-[2.5rem] sm:text-4xl md:text-5xl font-bold text-indigo-600 text-center animate-pulse select-none leading-tight whitespace-pre-line">
            {language === 'en'
              ? 'Touch the screen\nto start your order'
              : 'í™”ë©´ì„ í„°ì¹˜í•´\nì£¼ë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”'}
          </p>
        </div>
      )}

      {isCapturing ? (
        <div className="bg-indigo-100 rounded-lg border border-indigo-300 p-2 mt-2 shadow-sm">
          <p className="text-sm text-indigo-900 mb-1">
            {language === 'en' ? 'Recognizing speechâ€¦' : 'ìŒì„± ì¸ì‹ ì¤‘â€¦'}
          </p>
        </div>
      ) : (
        <div className="flex flex-col items-center">
          <p className="text-sm text-indigo-600">
            {listening ? (
              language === 'en' ? (
                <>
                  Listening for
                  <br />
                  the keywordâ€¦
                </>
              ) : (
                <>
                  í‚¤ì›Œë“œ ë§ë‘ì•„
                  <br />
                  ê°ì§€ì¤‘â€¦
                </>
              )
            ) : language === 'en' ? (
              'Waitingâ€¦'
            ) : (
              'ëŒ€ê¸° ì¤‘â€¦'
            )}
          </p>
        </div>
      )}
    </div>
  );
};

export default Voice;
