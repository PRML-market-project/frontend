import { useEffect, useState, useRef, useCallback } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import { useChatStore } from '@/features/chat/store/chatStore';
import { useVoiceStore } from '../store/voiceStore';
import { useGpt } from '../hooks/useGpt';
import { useLanguageStore } from '@/store/languageStore';
import { useParams } from 'react-router-dom';

const apiUrl = import.meta.env.VITE_GPT_API_URL;

const Voice = () => {
  const { listening, transcript, resetTranscript } = useSpeechRecognition();

  const {
    isCovered,
    setIsCovered,
    // isMicOn, // í•«ì›Œë“œ ë°©ì‹ì´ ì•„ë‹ˆë¯€ë¡œ storeì˜ isMicOn ìƒíƒœë³´ë‹¤ ë¡œì»¬ listening ìƒíƒœê°€ ë” ì§ê´€ì ì¼ ìˆ˜ ìˆìœ¼ë‚˜, UI ìœ ì§€ë¥¼ ìœ„í•´ ì‚¬ìš©
    startMic, // store í•¨ìˆ˜ ëŒ€ì‹  ì§ì ‘ SpeechRecognitionì„ ì œì–´í•©ë‹ˆë‹¤.
    stopMic
  } = useVoiceStore();

  const [isProcessing, setIsProcessing] = useState(false);
  const [capturedText, setCapturedText] = useState('');

  // Refs (í•«ì›Œë“œ ê´€ë ¨ Ref ì œê±°)
  const lastTextTimeRef = useRef<number>(0);

  // ğŸ”¥ [ì¤‘ìš”] ì¤‘ë³µ ì „ì†¡ ë°©ì§€ìš© Ref
  const isSendingRef = useRef(false);

  const { adminId, kioskId } = useParams();
  const { language } = useLanguageStore();
  const langCode = language === 'en' ? 'en-US' : 'ko-KR';

  const [devInput, setDevInput] = useState('');

  // KEYWORDS ë°°ì—´ ì œê±°ë¨

  const addMessage = useChatStore((state) => state.addMessage);
  const updateLastMessage = useChatStore((state) => state.updateLastMessage);
  const setIsCapturing = useChatStore((state) => state.setIsCapturing);
  const isCapturing = useChatStore((state) => state.isCapturing);

  const { sendTextToApi } = useGpt({ apiUrl });

  // ğŸ¤ ë§ˆì´í¬ ë²„íŠ¼ í•¸ë“¤ëŸ¬ (ìˆ˜ì •ë¨: í•«ì›Œë“œ ì—†ì´ ì¦‰ì‹œ ì‹œì‘/ì¤‘ì§€)
  const handleToggleMic = useCallback(async () => {
    try {
      // ì´ë¯¸ ë“£ê³  ìˆê±°ë‚˜ ìº¡ì²˜ ì¤‘ì´ë¼ë©´ ì¤‘ì§€
      if (listening || isCapturing) {
        SpeechRecognition.stopListening();
        setIsCapturing(false);
        setIsProcessing(false);
        // í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ì¦‰ì‹œ ì „ì†¡ ë¡œì§ì„ ë„£ì„ ìˆ˜ë„ ìˆì§€ë§Œ,
        // ë³´í†µ ë§í•˜ë‹¤ ëŠìœ¼ë©´ ì•„ë˜ ë¬´ìŒ ê°ì§€ ë¡œì§ì´ë‚˜ ì „ì†¡ ë¡œì§ì´ ì²˜ë¦¬í•˜ë„ë¡ ë‘¡ë‹ˆë‹¤.
        return;
      }

      // ì‹œì‘ ë¡œì§
      resetTranscript();      // ê¸°ì¡´ ìë§‰ ì´ˆê¸°í™”
      setIsCapturing(true);   // ìº¡ì²˜ ìƒíƒœ ì‹œì‘
      setIsProcessing(true);  // ì²˜ë¦¬ ì¤‘ ìƒíƒœ
      setCapturedText('');
      lastTextTimeRef.current = Date.now();

      // ë¹ˆ ì‚¬ìš©ì ë§í’ì„  ì¦‰ì‹œ ìƒì„±
      addMessage({
        text: '...', // í˜¹ì€ ë¹ˆ ë¬¸ìì—´
        isUser: true,
        timestamp: Date.now(),
      });

      // ìŒì„± ì¸ì‹ ì‹œì‘
      await SpeechRecognition.startListening({
        continuous: true,
        language: langCode
      });

    } catch (e) {
      console.error('Mic toggle failed:', e);
    }
  }, [listening, isCapturing, langCode, resetTranscript, setIsCapturing, addMessage]);

  /**
   * âœ… DEV ëª¨ë“œ: í‚¤ë³´ë“œ ì…ë ¥ì„ WebSpeech íë¦„ì²˜ëŸ¼ ì²˜ë¦¬
   */
  const runDevAsIfWebSpeech = useCallback(async (fullText: string) => {
    if (isSendingRef.current) return;
    isSendingRef.current = true;

    const now = Date.now();

    setIsProcessing(true);
    setIsCapturing(true);
    setCapturedText('');
    lastTextTimeRef.current = now;

    // í•«ì›Œë“œ ê´€ë ¨ ref ì„¤ì • ì œê±°ë¨

    addMessage({
      text: '',
      isUser: true,
      timestamp: now,
    });

    updateLastMessage(fullText);
    setCapturedText(fullText);
    lastTextTimeRef.current = Date.now();

    try {
      await sendTextToApi(fullText, adminId, kioskId);
    } catch (err) {
      console.error('Error processing DEV input:', err);
    } finally {
      isSendingRef.current = false;
      setIsCapturing(false);
      setIsProcessing(false);
      resetTranscript();
      setCapturedText('');
    }
  }, [addMessage, updateLastMessage, sendTextToApi, adminId, kioskId, resetTranscript, setIsCapturing]);


  // ğŸ“ ì‹¤ì‹œê°„ ìŒì„± ê°ì§€ ë° í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ìˆ˜ì •ë¨: í‚¤ì›Œë“œ ìŠ¬ë¼ì´ì‹± ë¡œì§ ì œê±°)
  useEffect(() => {
    if (transcript && isCapturing) {
      lastTextTimeRef.current = Date.now();

      // í‚¤ì›Œë“œ ì˜ë¼ë‚´ê¸° ì—†ì´ ì „ì²´ transcript ì‚¬ìš©
      const currentText = transcript.trim();

      setCapturedText(currentText);
      updateLastMessage(currentText);
    }
  }, [transcript, isCapturing, updateLastMessage]);

  // ğŸ”‡ ë¬´ìŒ ê°ì§€ ë° ìë™ ì „ì†¡ (ê¸°ì¡´ ìœ ì§€)
  // ë§í•˜ë‹¤ê°€ 2ì´ˆê°„ ì¹¨ë¬µí•˜ë©´ ìë™ìœ¼ë¡œ ì „ì†¡
  useEffect(() => {
    if (!isCapturing) return;

    const checkInterval = setInterval(() => {
      const now = Date.now();
      // ë§ˆì§€ë§‰ ì…ë ¥ í›„ 2ì´ˆ ê²½ê³¼ ì‹œ
      if (now - lastTextTimeRef.current > 2000) {
        SpeechRecognition.stopListening(); // ë“£ê¸° ì¤‘ë‹¨
        setIsCapturing(false);
        setIsProcessing(false);

        if (capturedText) {
          sendTextToApi(capturedText, adminId, kioskId).catch((err) => {
            console.error('Error processing voice input:', err);
          });
        } else {
            // ì•„ë¬´ ë§ë„ ì•ˆ í•˜ê³  2ì´ˆ ì§€ë‚˜ë©´ ê·¸ëƒ¥ êº¼ì§ (ë¹ˆ ë§í’ì„  ì²˜ë¦¬ í•„ìš”ì‹œ ë¡œì§ ì¶”ê°€)
             resetTranscript();
        }

        // ìƒíƒœ ì´ˆê¸°í™”
        resetTranscript();
        setCapturedText('');
      }
    }, 100);
    return () => clearInterval(checkInterval);
  }, [isCapturing, capturedText, sendTextToApi, adminId, kioskId, resetTranscript, setIsCapturing]);

  // âŒ í‚¤ì›Œë“œ ê°ì§€ useEffect ì‚­ì œë¨ âŒ

  useEffect(() => {
    return () => {
      SpeechRecognition.stopListening();
    };
  }, []);

  return (
    <div className="p-4 h-fit flex flex-row items-end gap-3 justify-end">

      {/* 1. ë§ˆì´í¬ ë²„íŠ¼ */}
      {!isCovered && (
        <button
          type="button"
          onClick={handleToggleMic}
          className={`
            w-12 h-12 rounded-full shadow-lg flex items-center justify-center transition active:scale-95 flex-shrink-0
            ${listening ? 'bg-red-600 text-white animate-pulse' : 'bg-indigo-600 text-white hover:bg-indigo-700'}
          `}
          title={listening ? 'ë§ˆì´í¬ ë„ê¸°' : 'ë§ˆì´í¬ ì¼œê¸°'}
        >
          {listening ? 'â– ' : 'ğŸ¤'}
        </button>
      )}

      {/* 2. DEV ì „ìš© í‚¤ë³´ë“œ ì…ë ¥ UI */}
      {process.env.NODE_ENV === 'development' && (
        <div className="w-[300px] flex-shrink-0">
          <div className="p-2 rounded-lg border border-indigo-200 bg-white text-left shadow-sm">
            <div className="text-[10px] text-indigo-700 mb-1 font-semibold">
              Developer Input
            </div>
            <div className="flex gap-2">
              <textarea
                className="flex-1 p-2 border rounded-md text-sm resize-none focus:outline-indigo-500 bg-indigo-50"
                rows={1}
                placeholder="ì…ë ¥..."
                value={devInput}
                onChange={(e) => setDevInput(e.target.value)}
                onKeyDown={(e) => {
                  if (e.nativeEvent.isComposing) return;
                  if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    const text = devInput.trim();
                    if (!text) return;
                    setDevInput('');
                    runDevAsIfWebSpeech(text);
                  }
                }}
              />
              <button
                className="px-3 rounded-md bg-indigo-600 text-white text-sm hover:bg-indigo-700 font-bold whitespace-nowrap"
                disabled={isSendingRef.current}
                onClick={() => {
                  const text = devInput.trim();
                  if (!text) return;
                  setDevInput('');
                  runDevAsIfWebSpeech(text);
                }}
              >
                Send
              </button>
            </div>
          </div>
          <div className="mt-1 text-center">
            {isCapturing ? (
               <span className="text-xs text-indigo-600 animate-pulse font-bold">ì¸ì‹ ì¤‘...</span>
            ) : (
               <span className="text-[10px] text-gray-400">
                 {listening ? 'Listening...' : 'Click Mic to Speak'}
               </span>
            )}
          </div>
        </div>
      )}

      {isCovered && (
        <div
          className="fixed top-0 left-0 w-screen h-screen flex flex-col items-center justify-center bg-white/80 backdrop-blur-md z-50 cursor-pointer"
          onClick={() => {
            setIsCovered(false);
            // ì»¤ë²„ í´ë¦­ ì‹œ ë°”ë¡œ ì‹œì‘í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
            // handleToggleMic();
          }}
        >
          <p className="text-4xl font-bold text-indigo-600 animate-pulse">í„°ì¹˜í•˜ì—¬ ì‹œì‘</p>
        </div>
      )}
    </div>
  );
};

export default Voice;