import { useEffect, useState, useRef, useCallback } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import { useChatStore } from '@/features/chat/store/chatStore';
import { useVoiceStore } from '../store/voiceStore';
import { useGpt } from '../hooks/useGpt';
import { useLanguageStore } from '@/store/languageStore';
import { useParams } from 'react-router-dom';

const apiUrl = import.meta.env.VITE_GPT_API_URL;

const Voice = () => {
  const { listening, transcript, resetTranscript } = useSpeechRecognition();

  const { isCovered, setIsCovered } = useVoiceStore();

  const [isProcessing, setIsProcessing] = useState(false);
  const [capturedText, setCapturedText] = useState('');

  // UI ì œì–´ìš©
  const [isMicOn, setIsMicOn] = useState(false);

  // ì¹¨ë¬µ ê°ì§€ìš© Ref
  const lastTextTimeRef = useRef<number>(0);

  // ì¤‘ë³µ ì „ì†¡ ë°©ì§€ìš© Ref
  const isSendingRef = useRef(false);

  // âœ… ìµœì‹  í…ìŠ¤íŠ¸ë¥¼ í•­ìƒ refì— ì €ì¥ (stop ì‹œì ì— stateê°€ ëŠ¦ì–´ë„ ì „ì†¡ ê°€ëŠ¥)
  const latestTextRef = useRef<string>('');

  const { adminId, kioskId } = useParams();
  const { language } = useLanguageStore();
  const langCode = language === 'en' ? 'en-US' : 'ko-KR';

  // DEV ëª¨ë“œ ì…ë ¥ìš© State
  const [devInput, setDevInput] = useState('');

  const addMessage = useChatStore((state) => state.addMessage);
  const updateLastMessage = useChatStore((state) => state.updateLastMessage);
  const setIsCapturing = useChatStore((state) => state.setIsCapturing);
  const isCapturing = useChatStore((state) => state.isCapturing);

  const { sendTextToApi } = useGpt({ apiUrl });

  // âœ… ì†Œí”„íŠ¸ stop: ìµœì¢… transcript í™•ì • ì´ë²¤íŠ¸ê°€ ì˜¤ë„ë¡ stopë§Œ
  const stopSoft = useCallback(() => {
    try {
      SpeechRecognition.stopListening();
    } catch {
      // ignore
    }
    setIsMicOn(false);
    setIsCapturing(false);
    setIsProcessing(false);
  }, [setIsCapturing]);

  // âœ… í•˜ë“œ stop: ê¼¬ì˜€ì„ ë•Œë§Œ abort+stop
  const stopHard = useCallback(() => {
    try {
      SpeechRecognition.abortListening();
      SpeechRecognition.stopListening();
    } catch {
      // ignore
    }
    setIsMicOn(false);
    setIsCapturing(false);
    setIsProcessing(false);
  }, [setIsCapturing]);

  // ğŸ¤ ë§ˆì´í¬ ë²„íŠ¼ í•¸ë“¤ëŸ¬
  const handleToggleMic = useCallback(async () => {
    try {
      // ====== ìˆ˜ë™ ì¢…ë£Œ ======
      if (isMicOn || listening || isCapturing) {
        // âœ… abort ì“°ë©´ ìµœì¢… ê²°ê³¼ê°€ ë‚ ì•„ê°ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ stopë§Œ
        stopSoft();

        // âœ… stop ì§í›„ ìµœì¢… transcriptê°€ ë“¤ì–´ì˜¤ëŠ” í™˜ê²½ì´ ìˆì–´ ì ê¹ ëŒ€ê¸°
        await new Promise((r) => setTimeout(r, 250));

        const text = (latestTextRef.current || capturedText || transcript || '').trim();

        if (text && adminId && kioskId) {
          await sendTextToApi(text, adminId, kioskId);
        }

        resetTranscript();
        setCapturedText('');
        latestTextRef.current = '';
        return;
      }

      // ====== ì‹œì‘ ======
      resetTranscript();
      setIsCapturing(true);
      setIsProcessing(true);
      setCapturedText('');
      latestTextRef.current = '';
      lastTextTimeRef.current = Date.now();

      // ë¹ˆ ì‚¬ìš©ì ë§í’ì„  ìƒì„±
      addMessage({
        text: '...',
        isUser: true,
        timestamp: Date.now(),
      });

      // âœ… startListening ì„±ê³µ ì´í›„ì—ë§Œ isMicOn=true
      SpeechRecognition.startListening({
        continuous: true,
        language: langCode,
        interimResults: true, // âœ… ë°°í¬ì—ì„œ ì¤‘ê°„ transcriptê°€ ëœ ì˜¤ëŠ” ê²½ìš° ëŒ€ë¹„
      });

      setIsMicOn(true);
    } catch (e) {
      console.error('Mic toggle failed:', e);
      // ì‹œì‘ ì‹¤íŒ¨ ì‹œ í•˜ë“œ ì •ë¦¬
      stopHard();
    }
  }, [
    isMicOn,
    listening,
    isCapturing,
    langCode,
    resetTranscript,
    setIsCapturing,
    addMessage,
    capturedText,
    transcript,
    adminId,
    kioskId,
    sendTextToApi,
    stopSoft,
    stopHard,
  ]);

  /**
   * DEV ëª¨ë“œ: í‚¤ë³´ë“œ ì…ë ¥ì„ WebSpeech íë¦„ì²˜ëŸ¼ ì²˜ë¦¬
   */
  const runDevAsIfWebSpeech = useCallback(
    async (fullText: string) => {
      if (isSendingRef.current) return;
      isSendingRef.current = true;

      const now = Date.now();

      setIsProcessing(true);
      setIsCapturing(true);
      setCapturedText('');
      latestTextRef.current = '';
      lastTextTimeRef.current = now;

      addMessage({
        text: '',
        isUser: true,
        timestamp: now,
      });

      updateLastMessage(fullText);
      setCapturedText(fullText);
      latestTextRef.current = fullText;
      lastTextTimeRef.current = Date.now();

      try {
        if (adminId && kioskId) {
          await sendTextToApi(fullText, adminId, kioskId);
        }
      } catch (err) {
        console.error('Error processing DEV input:', err);
      } finally {
        isSendingRef.current = false;
        setIsCapturing(false);
        setIsProcessing(false);
        resetTranscript();
        setCapturedText('');
        latestTextRef.current = '';
      }
    },
    [addMessage, updateLastMessage, sendTextToApi, adminId, kioskId, resetTranscript, setIsCapturing]
  );

  // ğŸ“ ì‹¤ì‹œê°„ ìŒì„± ê°ì§€ ë° í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (isCapturing) {
      const currentText = (transcript || '').trim();
      if (currentText) {
        lastTextTimeRef.current = Date.now();
        setCapturedText(currentText);
        latestTextRef.current = currentText; // âœ… ref ê°±ì‹ 
        updateLastMessage(currentText);
      }
    }
  }, [transcript, isCapturing, updateLastMessage]);

  // ğŸ”‡ ë¬´ìŒ ê°ì§€ ë° ìë™ ì „ì†¡
  useEffect(() => {
    if (!isCapturing) return;

    const checkInterval = setInterval(() => {
      const now = Date.now();

      if (now - lastTextTimeRef.current > 2000) {
        // âœ… ìë™ ì¢…ë£Œë„ stopSoftë¡œ ìµœì¢… í™•ì • ìœ ë„
        stopSoft();

        const text = (latestTextRef.current || capturedText || transcript || '').trim();

        if (text && adminId && kioskId) {
          sendTextToApi(text, adminId, kioskId).catch((err) => {
            console.error('Error processing voice input:', err);
          });
        } else {
          resetTranscript();
        }

        resetTranscript();
        setCapturedText('');
        latestTextRef.current = '';
      }
    }, 100);

    return () => clearInterval(checkInterval);
  }, [isCapturing, capturedText, transcript, sendTextToApi, adminId, kioskId, resetTranscript, stopSoft]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ í•˜ë“œ ì •ë¦¬(ê¼¬ì„ ë°©ì§€)
  useEffect(() => {
    return () => {
      stopHard();
    };
  }, [stopHard]);

  return (
    <div className="h-full flex flex-col items-center justify-center gap-2 p-2">
      {/* 1. ë§ˆì´í¬ ë²„íŠ¼ */}
      {!isCovered && (
        <button
          type="button"
          onClick={handleToggleMic}
          className={`
            w-14 h-14 rounded-full shadow-lg flex items-center justify-center transition active:scale-95 flex-shrink-0
            ${isMicOn ? 'bg-[var(--color-red-600)] text-white animate-pulse' : 'bg-[var(--color-indigo-600)] text-white hover:bg-[var(--color-indigo-700)]'}
          `}
          title={isMicOn ? 'ë§ˆì´í¬ ë„ê¸°' : 'ë§ˆì´í¬ ì¼œê¸°'}
        >
          {isMicOn ? 'â– ' : 'ğŸ¤'}
        </button>
      )}

      {/* 2. DEV ì „ìš© í‚¤ë³´ë“œ ì…ë ¥ UI */}
      {import.meta.env.DEV && (
        <div className="w-full max-w-[200px] flex-shrink-0">
          <div className="p-2 rounded-lg border border-[var(--color-indigo-200)] bg-white text-left shadow-sm">
            <div className="text-[10px] text-[var(--color-indigo-700)] mb-1 font-semibold">Developer Input</div>
            <div className="flex gap-2">
              <textarea
                className="flex-1 p-2 border rounded-md text-sm resize-none focus:outline-[var(--color-indigo-500)] bg-[var(--color-indigo-50)]"
                rows={1}
                placeholder="ì…ë ¥..."
                value={devInput}
                onChange={(e) => setDevInput(e.target.value)}
                onKeyDown={(e) => {
                  if (e.nativeEvent.isComposing) return;
                  if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    const text = devInput.trim();
                    if (!text) return;
                    setDevInput('');
                    runDevAsIfWebSpeech(text);
                  }
                }}
              />
              <button
                className="px-3 rounded-md bg-[var(--color-indigo-600)] text-white text-sm hover:bg-[var(--color-indigo-700)] font-bold whitespace-nowrap"
                disabled={isSendingRef.current}
                onClick={() => {
                  const text = devInput.trim();
                  if (!text) return;
                  setDevInput('');
                  runDevAsIfWebSpeech(text);
                }}
              >
                Send
              </button>
            </div>
          </div>
          <div className="mt-1 text-center">
            {isCapturing ? (
              <span className="text-xs text-[var(--color-indigo-600)] animate-pulse font-bold">ì¸ì‹ ì¤‘...</span>
            ) : (
              <span className="text-[10px] text-[var(--color-gray-400)]">{isMicOn ? 'Listening...' : 'Click Mic to Speak'}</span>
            )}
          </div>
        </div>
      )}

      {isCovered && (
        <div
          className="fixed top-0 left-0 w-screen h-screen flex flex-col items-center justify-center bg-white/80 backdrop-blur-md z-50 cursor-pointer"
          onClick={() => {
            setIsCovered(false);
          }}
        >
          <p className="text-4xl font-bold text-[var(--color-indigo-600)] animate-pulse">í„°ì¹˜í•˜ì—¬ ì‹œì‘</p>
        </div>
      )}
    </div>
  );
};

export default Voice;
