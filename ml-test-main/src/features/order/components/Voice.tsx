import { useEffect, useState, useRef, useCallback } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import { useChatStore } from '@/features/chat/store/chatStore';
import { useVoiceStore } from '../store/voiceStore';
import { useGpt } from '../hooks/useGpt';
import { useLanguageStore } from '@/store/languageStore';
import { useParams } from 'react-router-dom';

const apiUrl = import.meta.env.VITE_GPT_API_URL;

const Voice = () => {
  const { listening, transcript, resetTranscript } = useSpeechRecognition();

  const {
    isCovered,
    setIsCovered,
    isMicOn,
    startHotwordDetection,
    stopHotwordDetection,
    startMic,
    stopMic
  } = useVoiceStore();

  const [isProcessing, setIsProcessing] = useState(false);
  const [capturedText, setCapturedText] = useState('');

  // Refs
  const lastTextTimeRef = useRef<number>(0);
  const keywordIndexRef = useRef<number>(-1);
  const detectedKeywordRef = useRef<string | null>(null);

  // ğŸ”¥ [ì¤‘ìš”] ì¤‘ë³µ ì „ì†¡ ë°©ì§€ìš© Ref ì¶”ê°€
  const isSendingRef = useRef(false);

  const { adminId, kioskId } = useParams();
  const { language } = useLanguageStore();
  const langCode = language === 'en' ? 'en-US' : 'ko-KR';

  const [devInput, setDevInput] = useState('');

  const KEYWORDS = language === 'en'
    ? ['malang', 'hello', 'Malang']
    : ['ë§ë‘ì•„', 'ë¹¨ë‘ì•„', 'ë¹¨ë‘ ì™€', 'ë§ë‘í•œ', 'ë¹¨ë¦¬ ì™€', 'ë¹¨ë¦¬ì™€', 'ë¹¨ë‘ì™€', 'ëª°ë¼', 'ëª°ë‘', 'ë§ë‘ì€', 'ë¹¨ë‘'];

  const addMessage = useChatStore((state) => state.addMessage);
  const updateLastMessage = useChatStore((state) => state.updateLastMessage);
  const setIsCapturing = useChatStore((state) => state.setIsCapturing);
  const isCapturing = useChatStore((state) => state.isCapturing);

  const { sendTextToApi } = useGpt({ apiUrl });

  // ë§ˆì´í¬ í† ê¸€ í•¸ë“¤ëŸ¬
  const handleToggleMic = useCallback(async () => {
    try {
      if (isMicOn) {
        stopMic?.();
        stopHotwordDetection?.();
        return;
      }
      await startHotwordDetection?.();
      await startMic?.({ lang: langCode });
    } catch (e) {
      console.error('Mic/Hotword toggle failed:', e);
    }
  }, [isMicOn, langCode, startHotwordDetection, stopHotwordDetection, startMic, stopMic]);

  /**
   * âœ… DEV ëª¨ë“œ: í‚¤ë³´ë“œ ì…ë ¥ì„ WebSpeech íë¦„ì²˜ëŸ¼ ì²˜ë¦¬
   * ğŸ”¥ ìˆ˜ì •ì‚¬í•­: setTimeout ì œê±° + ì¤‘ë³µ ì „ì†¡ ë°©ì§€(isSendingRef) ì ìš©
   */
  const runDevAsIfWebSpeech = useCallback(async (fullText: string) => {
    // 1. ì´ë¯¸ ì „ì†¡ ì¤‘ì´ë©´ ë¬´ì‹œ (ì¤‘ë³µ ë°©ì§€ í•µì‹¬)
    if (isSendingRef.current) return;
    isSendingRef.current = true;

    const now = Date.now();

    // 2. ìƒíƒœ ì„¤ì •
    setIsProcessing(true);
    setIsCapturing(true);
    setCapturedText('');
    lastTextTimeRef.current = now;
    keywordIndexRef.current = 0;
    detectedKeywordRef.current = 'DEV';

    // 3. ë¹ˆ ì‚¬ìš©ì ë§í’ì„  ìƒì„± (ì˜¤ë¥¸ìª½ íŒŒë€ìƒ‰)
    addMessage({
      text: '',
      isUser: true,
      timestamp: now,
    });

    // 4. ğŸ”¥ [ì¤‘ìš”] setTimeout ì—†ì´ ì¦‰ì‹œ ì—…ë°ì´íŠ¸!
    // ì´ë ‡ê²Œ í•´ì•¼ APIê°€ ë¡œë”© ë§í’ì„ ì„ ë§Œë“¤ê¸° ì „ì— 'ë‚´ ë©”ì‹œì§€'ê°€ ì™„ì„±ë©ë‹ˆë‹¤.
    updateLastMessage(fullText);
    setCapturedText(fullText);
    lastTextTimeRef.current = Date.now();

    // 5. API í˜¸ì¶œ
    try {
      await sendTextToApi(fullText, adminId, kioskId);
    } catch (err) {
      console.error('Error processing DEV input:', err);
    } finally {
      // 6. ì¢…ë£Œ ì²˜ë¦¬ ë° ë½ í•´ì œ
      isSendingRef.current = false; // ì „ì†¡ ì™„ë£Œ, ë½ í•´ì œ
      setIsCapturing(false);
      setIsProcessing(false);
      resetTranscript();
      keywordIndexRef.current = -1;
      detectedKeywordRef.current = null;
      setCapturedText('');
    }
  }, [addMessage, updateLastMessage, sendTextToApi, adminId, kioskId, resetTranscript, setIsCapturing]);

  // ... (ì´í•˜ useEffect ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼) ...
  // ì‹¤ì‹œê°„ ìŒì„± ê°ì§€
  useEffect(() => {
    if (transcript) {
      lastTextTimeRef.current = Date.now();
      if (isCapturing && keywordIndexRef.current !== -1 && detectedKeywordRef.current) {
        const textAfterKeyword = transcript
          .slice(keywordIndexRef.current + detectedKeywordRef.current.length)
          .trim();
        setCapturedText(textAfterKeyword);
        updateLastMessage(textAfterKeyword);
      }
    }
  }, [transcript, isCapturing, updateLastMessage]);

  // ë¬´ìŒ ê°ì§€ ë° ìë™ ì „ì†¡
  useEffect(() => {
    if (!isCapturing) return;
    const checkInterval = setInterval(() => {
      const now = Date.now();
      if (now - lastTextTimeRef.current > 2000) {
        setIsCapturing(false);
        setIsProcessing(false);
        if (capturedText) {
          sendTextToApi(capturedText, adminId, kioskId).catch((err) => {
            console.error('Error processing voice input:', err);
          });
        }
        resetTranscript();
        keywordIndexRef.current = -1;
        detectedKeywordRef.current = null;
        setCapturedText('');
      }
    }, 100);
    return () => clearInterval(checkInterval);
  }, [isCapturing, capturedText, sendTextToApi, adminId, kioskId, resetTranscript, setIsCapturing]);

  // í‚¤ì›Œë“œ ê°ì§€
  useEffect(() => {
    if (!transcript || isProcessing) return;
    let foundKeyword: string | null = null;
    let foundIndex = -1;
    for (const keyword of KEYWORDS) {
      const idx = transcript.indexOf(keyword);
      if (idx !== -1) {
        foundKeyword = keyword;
        foundIndex = idx;
        break;
      }
    }
    if (foundKeyword && keywordIndexRef.current === -1) {
      setIsProcessing(true);
      setIsCapturing(true);
      setCapturedText('');
      lastTextTimeRef.current = Date.now();
      keywordIndexRef.current = foundIndex;
      detectedKeywordRef.current = foundKeyword;
      addMessage({
        text: '',
        isUser: true,
        timestamp: Date.now(),
      });
    }
  }, [transcript, isProcessing, KEYWORDS, addMessage, setIsCapturing]);

  useEffect(() => {
    return () => {
      SpeechRecognition.stopListening();
    };
  }, []);

  return (
    <div className="p-4 h-fit flex flex-row items-end gap-3 justify-end">

      {/* 1. ë§ˆì´í¬ ë²„íŠ¼ */}
      {!isCovered && (
        <button
          type="button"
          onClick={handleToggleMic}
          className={`
            w-12 h-12 rounded-full shadow-lg flex items-center justify-center transition active:scale-95 flex-shrink-0
            ${isMicOn ? 'bg-red-600 text-white' : 'bg-indigo-600 text-white hover:bg-indigo-700'}
          `}
          title={isMicOn ? 'ë§ˆì´í¬ ë„ê¸°' : 'ë§ˆì´í¬ ì¼œê¸°'}
        >
          {isMicOn ? 'â– ' : 'ğŸ¤'}
        </button>
      )}

      {/* 2. DEV ì „ìš© í‚¤ë³´ë“œ ì…ë ¥ UI */}
      {process.env.NODE_ENV === 'development' && (
        <div className="w-[300px] flex-shrink-0">
          <div className="p-2 rounded-lg border border-indigo-200 bg-white text-left shadow-sm">
            <div className="text-[10px] text-indigo-700 mb-1 font-semibold">
              Developer Input
            </div>
            <div className="flex gap-2">
              <textarea
                className="flex-1 p-2 border rounded-md text-sm resize-none focus:outline-indigo-500 bg-indigo-50"
                rows={1}
                placeholder="ì…ë ¥..."
                value={devInput}
                onChange={(e) => setDevInput(e.target.value)}
                onKeyDown={(e) => {
                  if (e.nativeEvent.isComposing) return;
                  if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    const text = devInput.trim();
                    if (!text) return;
                    setDevInput('');
                    runDevAsIfWebSpeech(text);
                  }
                }}
              />
              <button
                className="px-3 rounded-md bg-indigo-600 text-white text-sm hover:bg-indigo-700 font-bold whitespace-nowrap"
                // ğŸ”¥ ì „ì†¡ ì¤‘ì´ë©´ ë²„íŠ¼ ë¹„í™œì„±í™” (ì„ íƒ ì‚¬í•­)
                disabled={isSendingRef.current}
                onClick={() => {
                  const text = devInput.trim();
                  if (!text) return;
                  setDevInput('');
                  runDevAsIfWebSpeech(text);
                }}
              >
                Send
              </button>
            </div>
          </div>
          <div className="mt-1 text-center">
            {isCapturing ? (
               <span className="text-xs text-indigo-600 animate-pulse font-bold">ì¸ì‹ ì¤‘...</span>
            ) : (
               <span className="text-[10px] text-gray-400">
                 {listening ? 'Listening...' : 'Waiting...'}
               </span>
            )}
          </div>
        </div>
      )}

      {isCovered && (
        <div
          className="fixed top-0 left-0 w-screen h-screen flex flex-col items-center justify-center bg-white/80 backdrop-blur-md z-50 cursor-pointer"
          onClick={() => {
            setIsCovered(false);
            return SpeechRecognition.startListening({ continuous: true, language: langCode });
          }}
        >
          <p className="text-4xl font-bold text-indigo-600 animate-pulse">í„°ì¹˜í•˜ì—¬ ì‹œì‘</p>
        </div>
      )}
    </div>
  );
};

export default Voice;